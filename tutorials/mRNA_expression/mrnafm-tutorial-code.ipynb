{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# mRNA-FM Tutorial",
   "id": "d3b9952c3fb71cae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Workflow of our tutorial\n",
    "\n",
    "**Preparation**\n",
    "1. install the RNA-FM package\n",
    "2. load the necessary libraries\n",
    "\n",
    "**Task 1. RNA family clustering**\n",
    "\n",
    "Goal: to demonstrate that RNA-FM embeddings are biologically meaningful\n",
    "\n",
    "1. read RNA sequences for each family from FASTA files\n",
    "2. generate the RNA-FM embeddings for each sequence\n",
    "3. t-SNE dimension reduction on the generated embeddings\n",
    "4. plot the embeddings in the 2D space\n",
    "\n",
    "**Task 2. RNA type classification**\n",
    "\n",
    "Goal: to demonstrate how to use RNA-FM for downstream applications\n",
    "\n",
    "1. read RNA sequences for each type from a FASTA file\n",
    "2. generate RNA-FM embeddings for each sequence\n",
    "3. build the dataset and model\n",
    "4. train and validate the model\n",
    "5. test the model on a dataset excluded from training"
   ],
   "id": "e5e343a17d79d7d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Install RNA-FM",
   "id": "91f3682a26141736"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!pip install rna-fm\n",
    "#!pip install -U numpy\n",
    "!pip install biopython"
   ],
   "id": "4a05e5fdb285406a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If pip install fails to install the required packages, we can also uncomment the following cell to install it from source.",
   "id": "ec758c6debb34a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# !git clone https://github.com/ml4bio/RNA-FM.git\n",
    "\n",
    "# !pwd\n",
    "# !ls\n",
    "# %cd /content/RNA-FM\n",
    "# !python setup.py install"
   ],
   "id": "e2d59ebadf6f2f35"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import fm  # for development with RNA-FM\n",
    "\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from Bio import SeqIO  # for file parsing\n",
    "\n",
    "from sklearn.manifold import TSNE  # for dimension reduction\n",
    "\n",
    "from sklearn.model_selection import train_test_split  # for splitting train/val/test\n",
    "\n",
    "from tqdm.notebook import tqdm  # for showing progress\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ],
   "id": "1cebd80883ef04a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!git clone https://github.com/Sanofi-Public/CodonBERT.git",
   "id": "148b979ca94110f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!head CodonBERT/benchmarks/CodonBERT/data/fine-tune/E.Coli_proteins.csv",
   "id": "c9e25934fe8e74c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    " if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print(f'using {device} device')\n",
    "\n",
    "data_file = 'CodonBERT/benchmarks/CodonBERT/data/fine-tune/E.Coli_proteins.csv'"
   ],
   "id": "b1d92d34e5340ec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Task. mRNA expression",
   "id": "20fb3c38267c01ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load the pretrained model",
   "id": "5fcf41d40ce17f26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# !gdown 1zflX5hHTxuwqcZm6A1npq7ubP8m7LdNX",
   "id": "c72b329af12d9b58"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load mRNA-FM model\n",
    "fm_model, alphabet = fm.pretrained.mrna_fm_t12()   #Path(data_dir, 'RNA-FM_pretrained.pth'))\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "fm_model.to(device)  # use GPU if available\n",
    "\n",
    "fm_model.eval()  # disables dropout for deterministic results"
   ],
   "id": "5bcb4ad11666c8fa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e957c2b255008789"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load Model",
   "id": "67ae15c154ba5fae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You don't need to download it again if you have already done so for the previous task.",
   "id": "23a81f57c4254426"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# !gdown 1zflX5hHTxuwqcZm6A1npq7ubP8m7LdNX  # for Colab only",
   "id": "272a7269c698f77d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load mRNA-FM model\n",
    "fm_model, alphabet = fm.pretrained.mrna_fm_t12()   # rna_fm_t12(Path(data_dir, 'RNA-FM_pretrained.pth'))\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "fm_model.to(device)\n",
    "\n",
    "fm_model.eval()  # disables dropout for deterministic results"
   ],
   "id": "61af951c5ece07e0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load data",
   "id": "695a7ee8c0a0b1c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# load sequences and labels\n",
    "data_df = pd.read_csv(data_file)\n",
    "data_df = data_df[data_df[\"Value\"].isin([0, 2])]\n",
    "display(data_df)\n",
    "display(data_df.groupby(\"Split\")[\"Value\"].value_counts())\n",
    "\n",
    "raw_seqs = []\n",
    "labels = []\n",
    "for index, row in data_df.iterrows():\n",
    "  raw_seq = (str(index), row[\"Sequence\"])\n",
    "  raw_seqs.append(raw_seq)\n",
    "  labels.append(row[\"Value\"])"
   ],
   "id": "c0fad74844e0241d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# process binary labels (0: low expression; 1: high expression)\n",
    "labels = np.array(labels)\n",
    "labels = (labels == 2) * 1\n",
    "print(labels.shape)"
   ],
   "id": "14d7b2d3e033d50c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Extract embedding",
   "id": "2c449aeee72219cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "chunk_size = 1\n",
    "\n",
    "# pre-allocate the space to save memory\n",
    "token_embeddings = np.zeros((len(labels), 1280))\n",
    "\n",
    "# divide all the sequences into chunks for processing due to the GPU memory limit\n",
    "for i in tqdm(range(0, len(raw_seqs), chunk_size)):\n",
    "    data = raw_seqs[i:i+chunk_size]\n",
    "\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "\n",
    "    # use GPU\n",
    "    with torch.no_grad():\n",
    "        results = fm_model(batch_tokens.to(device), repr_layers=[12])\n",
    "\n",
    "    emb = results[\"representations\"][12].cpu().numpy()[:, 0,: ]\n",
    "\n",
    "    token_embeddings[i:i+chunk_size, :] = emb\n",
    "\n",
    "\n",
    "print(token_embeddings.shape)"
   ],
   "id": "fabb5e8fd1870b63"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Construct the dataset and classifier",
   "id": "105e03d37e54e824"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class RNATypeDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = embeddings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # use the cls token of the mRNA-FM embedding\n",
    "        return self.embeddings[idx], self.labels[idx]"
   ],
   "id": "dd05f2cfebcfe937"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class RNATypeClassifier(nn.Module):\n",
    "    def __init__(self, in_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(in_dim, num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ],
   "id": "57fc9a5f5259052e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# dataset split\n",
    "valid_value = data_df[\"Value\"].values != 1\n",
    "train_list = (data_df[\"Split\"].values == \"train\") & valid_value\n",
    "x_train = token_embeddings[train_list]\n",
    "y_train = labels[train_list]\n",
    "val_list = (data_df[\"Split\"].values == \"val\") & valid_value\n",
    "x_val = token_embeddings[val_list]\n",
    "y_val = labels[val_list]\n",
    "test_list = (data_df[\"Split\"].values == \"test\") & valid_value\n",
    "x_test = token_embeddings[test_list]\n",
    "y_test = labels[test_list]"
   ],
   "id": "63ddf3de4b9d424f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# hyper-parameters\n",
    "\n",
    "batch_size = 4\n",
    "lr = 1e-3\n",
    "epochs = 100"
   ],
   "id": "f3cb947a6bc53a95"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_dataset = RNATypeDataset(x_train, y_train)\n",
    "val_dataset = RNATypeDataset(x_val, y_val)\n",
    "test_dataset = RNATypeDataset(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "id": "7c2c101d7a7bde7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_class = 2\n",
    "in_dim = 1280\n",
    "model = RNATypeClassifier(in_dim, num_class).to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ],
   "id": "702b1735f32daffc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train the model",
   "id": "c4f0f99607a4988f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "max_val_acc = -1\n",
    "best_epoch = -1\n",
    "\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "\n",
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    # train the model\n",
    "    train_losses = []\n",
    "    train_preds = []\n",
    "    train_targets = []\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        x, y = x.to(device).float(), y.to(device).long()\n",
    "\n",
    "        # no need to apply the softmax function since it has been included in the loss function\n",
    "        y_pred = model(x)\n",
    "\n",
    "        # y_pred: (B, C) with class probabilities, y shape: (B,) with class indices\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        train_preds.append(torch.max(y_pred.detach(),1)[1])\n",
    "        train_targets.append(y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # validate the model\n",
    "    val_losses = []\n",
    "    val_preds = []\n",
    "    val_targets = []\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for batch in val_loader:\n",
    "        x, y = batch\n",
    "        x, y = x.to(device).float(), y.to(device).long()\n",
    "\n",
    "        y_pred = model(x)\n",
    "\n",
    "        # y_pred: (B, C) with class probabilities, y shape: (B,) with class indices\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        val_losses.append(loss.item())\n",
    "        val_preds.append(torch.max(y_pred.detach(),1)[1])\n",
    "        val_targets.append(y)\n",
    "\n",
    "    # calculate the accuracy\n",
    "    train_preds = torch.cat(train_preds, dim=0)\n",
    "    train_targets = torch.cat(train_targets, dim=0)\n",
    "    train_acc = (train_preds == train_targets).float().mean().cpu()\n",
    "\n",
    "    val_preds = torch.cat(val_preds, dim=0)\n",
    "    val_targets = torch.cat(val_targets, dim=0)\n",
    "    val_acc = (val_preds == val_targets).float().mean().cpu()\n",
    "\n",
    "    train_acc_history.append(train_acc)\n",
    "    val_acc_history.append(val_acc)\n",
    "\n",
    "    # save the model checkpoint for the best validation accuracy\n",
    "    if val_acc > max_val_acc:\n",
    "        torch.save({'model_state_dict': model.state_dict()}, 'rna_type_checkpoint.pt')\n",
    "        best_epoch = epoch\n",
    "        max_val_acc = val_acc\n",
    "\n",
    "    # show intermediate steps\n",
    "    if epoch % 20 == 1:\n",
    "        tqdm.write(f'epoch {epoch}/{epochs}: train loss={np.mean(train_loss_history):.6f}, '\n",
    "                   f'train acc={train_acc:.6f}, '\n",
    "                   f'val loss={np.mean(val_loss_history):.6f}, '\n",
    "                   f'val acc={val_acc:.6f}')\n",
    "\n",
    "    train_loss_history.append(np.mean(train_losses))\n",
    "    val_loss_history.append(np.mean(val_losses))"
   ],
   "id": "f561add89ca9cf6d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Visualize training results",
   "id": "1615cffc9d4606d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.plot(train_loss_history, label='train loss')\n",
    "plt.plot(val_loss_history, label='val loss')\n",
    "\n",
    "# the epoch with best validation loss\n",
    "plt.axvline(x=best_epoch, color='r', linestyle='--', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss History')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "id": "6d1b2dacadef1085"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.plot(train_acc_history, label='train accuracy')\n",
    "plt.plot(val_acc_history, label='val accuracy')\n",
    "\n",
    "# the epoch with best validation accuracy\n",
    "plt.axvline(x=best_epoch, color='r', linestyle='--', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy History')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "id": "48550b4e8b810b5e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test the model",
   "id": "158572792dd3b659"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# test the model\n",
    "test_preds = []\n",
    "\n",
    "model.load_state_dict(torch.load('rna_type_checkpoint.pt')['model_state_dict'])\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for batch in test_loader:\n",
    "    x, y = batch\n",
    "    x, y = x.to(device).float(), y.to(device).long()\n",
    "\n",
    "    output = model(x)\n",
    "\n",
    "    _, y_pred = torch.max(output.data, 1)  # argmax in y_pred\n",
    "    # print(y_pred.shape)\n",
    "\n",
    "    test_preds.append(y_pred.cpu().numpy())\n",
    "\n",
    "\n",
    "test_preds = np.concatenate(test_preds)\n",
    "\n",
    "total = len(y_test)\n",
    "correct = np.sum(test_preds == y_test)\n",
    "\n",
    "print(f'total number of test data: {total}, correct={correct}, test acc={correct/total:.4f}')"
   ],
   "id": "1bfbbf3c74890708"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e95f5c9de59daaaf"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
